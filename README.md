# FileReduce

Procesador de archivos de gran volumen (EDIFACT, XML, JSONL) optimizado para alto rendimiento y conversi√≥n a estructuras de datos modernas. Dise√±ado para integraci√≥n directa con bases de datos SQL Server y flujos de trabajo de datos masivos.

## üöÄ Instalaci√≥n

Para instalar la herramienta globalmente en tu sistema desde el c√≥digo fuente:

```bash
# Navega al directorio del proyecto
cd filereduce

# Instala el binario en tu PATH
cargo install --path .
```

*Aseg√∫rate de tener Rust instalado y el directorio de binarios de cargo en tu PATH.*

---

## üõ†Ô∏è Uso y Comandos

### 1. Ingesta a SQL Server (`insert`)

Carga archivos EDIFACT directamente a tu base de datos utilizando un procedimiento almacenado configurable. Soporta cargas masivas (batching) y transacciones.

**Configuraci√≥n (`config.yaml`)**
```yaml
ingest:
  connection_string: "server=tcp:myserver.database.windows.net,1433;database=myDB;user=user;password=pass;encrypt=true;trustServerCertificate=true;"
  procedure_name: "sp_EDI_Ingresar_Batch_Orders"
  json_param: "@JsonBatch"
  batch_size: 1000
```

#### Windows (PowerShell)
```powershell
filereduce insert --config config.yaml input.edifact
```

#### Linux / macOS (Bash)
```bash
filereduce insert --config config.yaml input.edifact
```

---

### 2. Procesamiento a Archivo (`process`)

Convierte archivos EDIFACT a formato JSONL (JSON Lines) para an√°lisis local o ingesti√≥n en otros sistemas (BigQuery, etc.).

#### Windows (PowerShell)
```powershell
# Proceso simple
filereduce process input.edifact output.jsonl -f edifact

# Con filtro de consulta (SQL-like)
filereduce process input.edifact output_filtered.jsonl -f edifact -q "doc_type = 'ORDERS' AND qty > 100"
```

#### Linux / macOS (Bash)
```bash
# Proceso simple
filereduce process input.edifact output.jsonl -f edifact

# Con filtro de consulta (SQL-like)
filereduce process input.edifact output_filtered.jsonl -f edifact -q "doc_type = 'ORDERS' AND qty > 100"
```

---

### 3. Conversi√≥n de Formatos (`convert`)

Utilidad r√°pida para transformar entre formatos soportados.

#### Windows (PowerShell)
```powershell
filereduce convert input.xml output.json --from xml --to json
```

#### Linux / macOS (Bash)
```bash
filereduce convert input.xml output.json --from xml --to json
```

---

## üèóÔ∏è Desarrollo

Para ejecutar pruebas de integraci√≥n y verificar el funcionamiento localmente:

**Windows / Linux / macOS**
```bash
cargo test
```

```
filereduce/
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ main.rs           # CLI entry point
‚îÇ   ‚îú‚îÄ‚îÄ cli.rs            # Argumentos de l√≠nea de comandos
‚îÇ   ‚îú‚îÄ‚îÄ processor.rs       # Procesador multi-formato
‚îÇ   ‚îú‚îÄ‚îÄ error.rs          # Manejo de errores
‚îÇ   ‚îú‚îÄ‚îÄ parser/           # Parsers espec√≠ficos
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ edifact.rs  # Parser EDIFACT
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ xml.rs       # Parser XML
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ json.rs      # Parser JSON
‚îÇ   ‚îî‚îÄ‚îÄ model/           # Modelos de datos
‚îî‚îÄ‚îÄ engine_filereduce/
    ‚îú‚îÄ‚îÄ src/
    ‚îÇ   ‚îú‚îÄ‚îÄ query/        # Motor de consultas
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ast.rs         # AST de consultas
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ parser.rs     # Parser SQL
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ aggregation.rs # Agregaciones
    ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ lexer.rs      # Lexer de consultas
    ‚îÇ   ‚îú‚îÄ‚îÄ executor/      # Ejecutor de consultas
    ‚îÇ   ‚îú‚îÄ‚îÄ row.rs         # Modelo de fila
    ‚îÇ   ‚îî‚îÄ‚îÄ reader/        # Lectura de datos
    ‚îú‚îÄ‚îÄ tests/            # Tests integrales y benchmarks
    ‚îî‚îÄ‚îÄ benches/          # Benchmarks de rendimiento
```

## Examples

### EDIFACT a JSONL

```bash
cargo run -- process tests/fixtures/sample.edifact output.jsonl
```

Salida:
```json
{"doc_type":"","number":"ORDER001","buyer":"BUYER001","seller":"SELLER001","lines":[{"sku":"SKU001","qty":10.0,"amount":100.0},{"sku":"SKU002","qty":20.0,"amount":200.0},{"sku":"SKU003","qty":15.0,"amount":150.0}]}
```

### XML a JSONL

```bash
cargo run -- process tests/fixtures/sample.xml output.jsonl
```

### Consultas complejas

```sql
-- Filtrar por cantidad y ordenar
qty > 10 ORDER BY qty DESC

-- B√∫squeda con patr√≥n
sku LIKE 'SKU%'

-- Rango num√©rico
qty BETWEEN 1 AND 100

-- M√∫ltiples condiciones
qty > 50 AND (sku = 'SKU001' OR sku = 'SKU002')
```

## Benchmarks

Ejecutar benchmarks para medir rendimiento:

```bash
# Benchmarks de procesamiento
cargo bench --bench processing_bench

# Benchmarks del motor de consultas
cargo bench --bench query_bench
```

## Optimizaciones

- **Streaming puro**: Sin acumulaci√≥n de datos en memoria
- **BufRead/BufWriter**: Buffered I/O para eficiencia
- **Regex caching**: LIKE expressions cacheadas
- **Lazy evaluation**: Procesamiento a demanda
- **Zero-copy**: Cuando sea posible, evitando copias innecesarias

## Tests

```bash
# Ejecutar todos los tests
cargo test

# Tests integrales
cargo test --test integration_tests

# Tests del motor de consultas
cargo test --package engine_filereduce
```

## Rendimiento

Procesamiento t√≠pico:
- **Archivos peque√±os** (<1MB): <100ms
- **Archivos medianos** (1-10MB): <1s
- **Archivos grandes** (10-100MB): <10s
- **Archivos masivos** (>100MB): ~1MB/s

## Roadmap

- [ ] Parser SQL completo con JOIN
- [ ] Agregaciones en CLI
- [ ] Paralelizaci√≥n de procesamiento
- [ ] Compresi√≥n de salida
- [ ] Soporte para CSV
- [ ] Soporte para otros formatos EDI
- [ ] Streaming HTTP
- [ ] Filtros din√°micos en tiempo real

## Contribuir

1. Fork del repositorio
2. Crear branch para feature
3. Hacer commits con mensajes claros
4. Pull request con descripci√≥n detallada

## License

MIT OR Apache-2.0

## Autor

Omar Fernando Jaramillo
